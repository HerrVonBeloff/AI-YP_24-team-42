{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HerrVonBeloff/AI-YP_24-team-42/blob/main/GAN/gan-text-plus-metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Библиотеки"
      ],
      "metadata": {
        "id": "CKwOO5FvkjQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:17:34.000821Z",
          "iopub.execute_input": "2024-12-09T04:17:34.001151Z",
          "iopub.status.idle": "2024-12-09T04:17:59.910111Z",
          "shell.execute_reply.started": "2024-12-09T04:17:34.001098Z",
          "shell.execute_reply": "2024-12-09T04:17:59.909087Z"
        },
        "id": "Pvwy0Mdc3A3i",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import inception_v3\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from scipy.linalg import sqrtm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:17:59.911989Z",
          "iopub.execute_input": "2024-12-09T04:17:59.912303Z",
          "iopub.status.idle": "2024-12-09T04:18:03.960516Z",
          "shell.execute_reply.started": "2024-12-09T04:17:59.912274Z",
          "shell.execute_reply": "2024-12-09T04:18:03.959742Z"
        },
        "id": "g0pBsK2Y4NQM",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Метрики"
      ],
      "metadata": {
        "id": "lIerVCzuk02R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inception_score(images, batch_size=32, splits=10):\n",
        "    \"\"\"\n",
        "    Расчёт Inception для набора картинок.\n",
        "\n",
        "    Args:\n",
        "        images (torch.Tensor): Тензор (N, 3, H, W).\n",
        "        batch_size (int): Размер батчей для InceptionV3.\n",
        "        splits (int): Количество разбиений для расчёта IS.\n",
        "\n",
        "    Returns:\n",
        "        float: Inception Score.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    N = len(images)\n",
        "\n",
        "    # Загрузка модели InceptionV3\n",
        "    inception_model = inception_v3(\n",
        "        weights=models.Inception_V3_Weights.DEFAULT, transform_input=False\n",
        "    ).to(device)\n",
        "    inception_model.eval()\n",
        "\n",
        "    # Предобработка картинок - убрал нормализацию - наш вход уже нормализован\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(\n",
        "                (299, 299)\n",
        "            )  # Необходимо, так как InceptionV3 обучалась именно на таких размерах\n",
        "        ]\n",
        "    )\n",
        "    images = torch.stack([transform(img) for img in images])\n",
        "\n",
        "    # Расчёт предсказаний\n",
        "    preds = []\n",
        "    for i in range(0, N, batch_size):\n",
        "        batch = images[i : i + batch_size].to(device)\n",
        "        with torch.no_grad():\n",
        "            preds.append(F.softmax(inception_model(batch), dim=1))\n",
        "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
        "\n",
        "    # Расчёт Inception Score\n",
        "    split_scores = []\n",
        "    for k in range(splits):\n",
        "        part = preds[k * (N // splits) : (k + 1) * (N // splits), :]\n",
        "        py = np.mean(part, axis=0)\n",
        "        scores = [np.sum(p * (np.log(p) - np.log(py))) for p in part]\n",
        "        split_scores.append(np.exp(np.mean(scores)))\n",
        "\n",
        "    return np.mean(split_scores), np.std(split_scores)"
      ],
      "metadata": {
        "id": "vAkdqXnWESGs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T04:18:03.961479Z",
          "iopub.execute_input": "2024-12-09T04:18:03.962000Z",
          "iopub.status.idle": "2024-12-09T04:18:03.975410Z",
          "shell.execute_reply.started": "2024-12-09T04:18:03.961962Z",
          "shell.execute_reply": "2024-12-09T04:18:03.974637Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fid(real_images, generated_images, batch_size=32):\n",
        "    \"\"\"\n",
        "    Вычисление Frechet Inception Distance (FID).\n",
        "\n",
        "    Args:\n",
        "        real_images (torch.Tensor): Тензор реальных изображений (N, 3, H, W).\n",
        "        generated_images (torch.Tensor): Тензор сгенерированных изображений (M, 3, H, W).\n",
        "        batch_size (int): Размер батча для модели InceptionV3, которая и рассчитывает метрики.\n",
        "\n",
        "    Returns:\n",
        "        float: FID.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inception_model = inception_v3(\n",
        "        weights=models.Inception_V3_Weights.DEFAULT, transform_input=False\n",
        "    ).to(device)\n",
        "    inception_model.eval()\n",
        "\n",
        "    def get_activations(images):\n",
        "        \"\"\"Извлечение фич из InceptionV3.\"\"\"\n",
        "        activations = []\n",
        "        for i in range(0, len(images), batch_size):\n",
        "            batch = images[i : i + batch_size].to(device)\n",
        "            with torch.no_grad():\n",
        "                features = inception_model(batch).detach()\n",
        "                activations.append(features.cpu())\n",
        "        return torch.cat(activations, dim=0).numpy()\n",
        "\n",
        "    # Обработка images - убрал нормализацию - наш вход уже нормализован\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(\n",
        "                (299, 299)\n",
        "            )  # Необходимо, так как InceptionV3 обучалась именно на таких размерах\n",
        "        ]\n",
        "    )\n",
        "    real_images = torch.stack([transform(img) for img in real_images])\n",
        "    generated_images = torch.stack([transform(img) for img in generated_images])\n",
        "\n",
        "    # Извлечение активаций (как я понимаю, из слоя нейросети InceptionV3)\n",
        "    act_real = get_activations(real_images)\n",
        "    act_gen = get_activations(generated_images)\n",
        "\n",
        "    # Расчёт статистик\n",
        "    mu_real, sigma_real = act_real.mean(axis=0), np.cov(act_real, rowvar=False)\n",
        "    mu_gen, sigma_gen = act_gen.mean(axis=0), np.cov(act_gen, rowvar=False)\n",
        "\n",
        "    # Расчёт FID\n",
        "    diff = mu_real - mu_gen\n",
        "    covmean = sqrtm(sigma_real @ sigma_gen).real\n",
        "    fid = diff.dot(diff) + np.trace(sigma_real + sigma_gen - 2 * covmean)\n",
        "\n",
        "    return fid"
      ],
      "metadata": {
        "id": "ytMj10mFg_gG",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T04:18:03.977537Z",
          "iopub.execute_input": "2024-12-09T04:18:03.980898Z",
          "iopub.status.idle": "2024-12-09T04:18:03.996040Z",
          "shell.execute_reply.started": "2024-12-09T04:18:03.980860Z",
          "shell.execute_reply": "2024-12-09T04:18:03.995363Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обработка входных данных"
      ],
      "metadata": {
        "id": "4C63g2Fa3ZYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "spacy.prefer_gpu()\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:18:03.999906Z",
          "iopub.execute_input": "2024-12-09T04:18:04.000299Z",
          "iopub.status.idle": "2024-12-09T04:18:07.699471Z",
          "shell.execute_reply.started": "2024-12-09T04:18:04.000261Z",
          "shell.execute_reply": "2024-12-09T04:18:07.698749Z"
        },
        "trusted": true,
        "id": "_G264O2K7fga"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:18:07.700562Z",
          "iopub.execute_input": "2024-12-09T04:18:07.701167Z",
          "iopub.status.idle": "2024-12-09T04:18:07.706211Z",
          "shell.execute_reply.started": "2024-12-09T04:18:07.701129Z",
          "shell.execute_reply": "2024-12-09T04:18:07.705477Z"
        },
        "trusted": true,
        "id": "RYLeM37N7fgb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformDataset(Dataset):\n",
        "    def __init__(self, df, new_size, nlp_model):\n",
        "        self.df = df\n",
        "        self.new_size = new_size\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(new_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ]\n",
        "        )\n",
        "        self.nlp_model = nlp_model\n",
        "\n",
        "    def __len__(self):  # без len загрузчик не работает\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Изображение\n",
        "        image = self.df[idx][\"image\"]  # загружаем изображение и текст по индексу\n",
        "        image = image.convert(\"RGB\")  # преобразуем в трехканальное\n",
        "        image = self.transform(image)  # применяем трансформации\n",
        "\n",
        "        # Текст\n",
        "        text = self.df[idx][\"text\"]\n",
        "        doc = nlp(text)  # Обработка текста\n",
        "        #lemmatized_tokens = [\n",
        "            #token.lemma_ for token in doc if not token.is_punct and not token.is_space\n",
        "        #]  # Лемматизация\n",
        "        vectors = [\n",
        "            token.vector.get()\n",
        "            for token in doc\n",
        "            if not token.is_punct and not token.is_space\n",
        "        ]  # Векторизация\n",
        "\n",
        "        return image, torch.tensor(np.mean(vectors, axis=0)[:vect_size])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:18:07.707611Z",
          "iopub.execute_input": "2024-12-09T04:18:07.707973Z",
          "iopub.status.idle": "2024-12-09T04:18:07.727492Z",
          "shell.execute_reply.started": "2024-12-09T04:18:07.707937Z",
          "shell.execute_reply": "2024-12-09T04:18:07.726736Z"
        },
        "id": "G3thU53c3bqs",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def text_plus_image(text, image):\n",
        "    embedding = text.unsqueeze(-1).unsqueeze(-1)\n",
        "    text_embedding_tensor = F.interpolate(\n",
        "        embedding, size=(28, 28), mode=\"bilinear\", align_corners=False\n",
        "    )\n",
        "    combined_input = torch.cat((text_embedding_tensor, image), dim=1)\n",
        "    return combined_input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:18:07.728556Z",
          "iopub.execute_input": "2024-12-09T04:18:07.728833Z",
          "iopub.status.idle": "2024-12-09T04:18:07.741184Z",
          "shell.execute_reply.started": "2024-12-09T04:18:07.728809Z",
          "shell.execute_reply": "2024-12-09T04:18:07.740506Z"
        },
        "id": "jf7l_Fj4VJHU",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"iamkaikai/amazing_logos_v4\", split=\"train\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:18:07.742674Z",
          "iopub.execute_input": "2024-12-09T04:18:07.743001Z",
          "iopub.status.idle": "2024-12-09T04:21:20.292282Z",
          "shell.execute_reply.started": "2024-12-09T04:18:07.742958Z",
          "shell.execute_reply": "2024-12-09T04:21:20.291574Z"
        },
        "id": "0W65k2574BsY",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Экземпляры моделей"
      ],
      "metadata": {
        "id": "KyEQO2xalA4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ГЕНЕРАТОР\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                z_dim + vect_size, 128, kernel_size=7, stride=1, padding=0, bias=False\n",
        "            ),  # тут получается не совсем монотонное расширение,\n",
        "            nn.BatchNorm2d(128),  # поэтому можно увеличить z_dim\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
        "        img = self.model(z)\n",
        "        return img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:20.295141Z",
          "iopub.execute_input": "2024-12-09T04:21:20.295386Z",
          "iopub.status.idle": "2024-12-09T04:21:20.301919Z",
          "shell.execute_reply.started": "2024-12-09T04:21:20.295362Z",
          "shell.execute_reply": "2024-12-09T04:21:20.300988Z"
        },
        "id": "QO_EktjSJQTk",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ДИСКРИМИНАТОР\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                3 + vect_size, 64, kernel_size=4, stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 1, kernel_size=7, stride=1, padding=0, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        validity = self.model(img)\n",
        "        return validity.view(-1, 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:20.302992Z",
          "iopub.execute_input": "2024-12-09T04:21:20.303344Z",
          "iopub.status.idle": "2024-12-09T04:21:20.319044Z",
          "shell.execute_reply.started": "2024-12-09T04:21:20.303296Z",
          "shell.execute_reply": "2024-12-09T04:21:20.318241Z"
        },
        "id": "IUjLDdmEJSHr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Параметры"
      ],
      "metadata": {
        "id": "xpUSwJC1lIws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = (3, 28, 28)  # форма изображений (3 канала, 28 на 28 пикселей)\n",
        "z_dim = 100  # размер входного вектора шума\n",
        "batch_size = 32  # размер батча\n",
        "epochs = 50  # количество эпох\n",
        "vect_size = 300  # размер вектора эмбеддинга"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:20.320085Z",
          "iopub.execute_input": "2024-12-09T04:21:20.320661Z",
          "iopub.status.idle": "2024-12-09T04:21:20.329670Z",
          "shell.execute_reply.started": "2024-12-09T04:21:20.320622Z",
          "shell.execute_reply": "2024-12-09T04:21:20.329029Z"
        },
        "id": "1Y8FD0p53Qh7",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = nn.BCELoss()\n",
        "generator = Generator(z_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:20.330488Z",
          "iopub.execute_input": "2024-12-09T04:21:20.330758Z",
          "iopub.status.idle": "2024-12-09T04:21:20.435372Z",
          "shell.execute_reply.started": "2024-12-09T04:21:20.330734Z",
          "shell.execute_reply": "2024-12-09T04:21:20.434707Z"
        },
        "id": "NND10J7m5IzV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TransformDataset(\n",
        "    dataset.select(range(296951, 397251)), new_size=(28, 28), nlp_model=nlp\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:20.436266Z",
          "iopub.execute_input": "2024-12-09T04:21:20.436499Z",
          "iopub.status.idle": "2024-12-09T04:21:20.449704Z",
          "shell.execute_reply.started": "2024-12-09T04:21:20.436477Z",
          "shell.execute_reply": "2024-12-09T04:21:20.449141Z"
        },
        "id": "lhfG7tAr6O46",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "ZUq-2SztlVOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(real_images, real_text):\n",
        "    real_images = real_images.to(device)\n",
        "    batch_size = real_images.size(0)\n",
        "    real_text = real_text.to(device)\n",
        "    # Тренировка дискриминатора\n",
        "    optimizer_D.zero_grad()\n",
        "\n",
        "    real_labels = torch.ones(batch_size, 1).to(device)\n",
        "    fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "    real_imagess = text_plus_image(real_text, real_images)\n",
        "    real_output = discriminator(real_imagess)\n",
        "    real_loss = adversarial_loss(real_output, real_labels)\n",
        "\n",
        "    z = torch.cat([torch.randn(batch_size, z_dim).to(device), real_text], 1)\n",
        "    fake_images = generator(z)\n",
        "    fake_imagess = text_plus_image(real_text, fake_images)\n",
        "    fake_output = discriminator(fake_imagess.detach())\n",
        "    fake_loss = adversarial_loss(fake_output, fake_labels)\n",
        "    d_loss = real_loss + fake_loss\n",
        "    d_loss.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "    # Тренировка генератора\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    fake_output = discriminator(fake_imagess)\n",
        "    g_loss = adversarial_loss(fake_output, real_labels)\n",
        "\n",
        "    g_loss.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "    return d_loss.item(), g_loss.item(), fake_images"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:20.450752Z",
          "iopub.execute_input": "2024-12-09T04:21:20.450993Z",
          "iopub.status.idle": "2024-12-09T04:21:20.460328Z",
          "shell.execute_reply.started": "2024-12-09T04:21:20.450970Z",
          "shell.execute_reply": "2024-12-09T04:21:20.459732Z"
        },
        "id": "N-VkgOxh6HEQ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "indexes_to_generate = np.random.randint(0, len(dataset), 16)\n",
        "text_to_generate = dataset.select(indexes_to_generate)\n",
        "text_to_generate = TransformDataset(text_to_generate, new_size=(28, 28), nlp_model=nlp)\n",
        "txt_to_generate = torch.empty(size=(16, 300))\n",
        "for idx, (i, j) in enumerate(text_to_generate):\n",
        "    txt_to_generate[idx] = j"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:20.461190Z",
          "iopub.execute_input": "2024-12-09T04:21:20.461473Z",
          "iopub.status.idle": "2024-12-09T04:21:25.758045Z",
          "shell.execute_reply.started": "2024-12-09T04:21:20.461449Z",
          "shell.execute_reply": "2024-12-09T04:21:25.757236Z"
        },
        "trusted": true,
        "id": "LpYYZ3Fn7fgf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch):\n",
        "    z = torch.cat([torch.randn(16, 100), txt_to_generate], 1).to(device)\n",
        "    generated_images = model(z).detach().cpu()\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "\n",
        "    for i in range(generated_images.size(0)):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(\n",
        "            generated_images[i].permute(1, 2, 0).numpy() * 0.5 + 0.5\n",
        "        )  # Денормализация\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.savefig(f\"/kaggle/working/image_at_epoch_{epoch}.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:25.759119Z",
          "iopub.execute_input": "2024-12-09T04:21:25.759382Z",
          "iopub.status.idle": "2024-12-09T04:21:25.764837Z",
          "shell.execute_reply.started": "2024-12-09T04:21:25.759358Z",
          "shell.execute_reply": "2024-12-09T04:21:25.763753Z"
        },
        "id": "WSnXu0wi6JRu",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "metrics_data = pd.DataFrame(\n",
        "    columns=[\n",
        "        \"epoch\",\n",
        "        \"g_loss\",\n",
        "        \"d_loss\",\n",
        "        \"inception_score_mean\",\n",
        "        \"inception_score_std\",\n",
        "        \"fid_score\",\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "nao3loQBRgrP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:25.766104Z",
          "iopub.execute_input": "2024-12-09T04:21:25.766452Z",
          "iopub.status.idle": "2024-12-09T04:21:29.242862Z",
          "shell.execute_reply.started": "2024-12-09T04:21:25.766414Z",
          "shell.execute_reply": "2024-12-09T04:21:29.241967Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, train_loader):\n",
        "    metrics_data = pd.DataFrame()\n",
        "    for epoch in range(epochs):\n",
        "        for i, (image, text) in enumerate(train_loader):\n",
        "            d_loss, g_loss, fake_images = train_step(image, text)\n",
        "            if i % 10 == 0:\n",
        "                print(\n",
        "                    f\"Epoch [{epoch}/{epochs - 1}] Batch [{i}/{len(train_loader) - 1}] D_loss: {d_loss:.4f}, G_loss: {g_loss:.4f}\"\n",
        "                )\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "\n",
        "            generate_and_save_images(generator, epoch)\n",
        "\n",
        "            is_mean, is_std = inception_score(\n",
        "                images=fake_images, batch_size=batch_size, splits=10\n",
        "            )\n",
        "            print(f\"Epoch {epoch} - Inception Score: {is_mean:.4f} ± {is_std:.4f}\")\n",
        "\n",
        "            fid_score = calculate_fid(\n",
        "                real_images=image, generated_images=fake_images, batch_size=batch_size\n",
        "            )\n",
        "            print(f\"Epoch {epoch} - FID Score: {fid_score:.4f}\")\n",
        "\n",
        "            new_row = pd.DataFrame(\n",
        "                [\n",
        "                    {\n",
        "                        \"epoch\": epoch,\n",
        "                        \"g_loss\": g_loss,\n",
        "                        \"d_loss\": d_loss,\n",
        "                        \"inception_score_mean\": is_mean,\n",
        "                        \"inception_score_std\": is_std,\n",
        "                        \"fid_score\": fid_score,\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "            metrics_data = pd.concat([metrics_data, new_row], ignore_index=True)\n",
        "\n",
        "        if (epoch % 5) == 0 or (epoch == epochs - 1):\n",
        "            torch.save(\n",
        "                generator.state_dict(),\n",
        "                os.path.join(\"/kaggle/working/generator_{}.pth\".format(epoch)),\n",
        "            )\n",
        "            torch.save(\n",
        "                discriminator.state_dict(),\n",
        "                os.path.join(\"/kaggle/working/discriminator_{}.pth\".format(epoch)),\n",
        "            )\n",
        "            metrics_data.to_csv(\"/kaggle/working/metrics_data.csv\", index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:29.244082Z",
          "iopub.execute_input": "2024-12-09T04:21:29.244812Z",
          "iopub.status.idle": "2024-12-09T04:21:29.256748Z",
          "shell.execute_reply.started": "2024-12-09T04:21:29.244766Z",
          "shell.execute_reply": "2024-12-09T04:21:29.255940Z"
        },
        "id": "KfSoq-296KhW",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train(epochs, train_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-09T04:21:29.257872Z",
          "iopub.execute_input": "2024-12-09T04:21:29.258148Z"
        },
        "trusted": true,
        "id": "yeudB8_S7fgg"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}