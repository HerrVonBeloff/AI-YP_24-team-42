<!-- профессиональное наставление от куратора по тому как проводить обучение / улучшение DL-моделей до июня -->

до конца проекта предлагается реализовать архитектуру, которрая способна генерировать логотипы в удовлетворительно хорошем качестве (где-то 256х256), 
обуславливаясь на описание желаемоого результата
на первом курсе магистратуры студенты не обладают огромным колмчеством навыков, поэтому требовать от вас реализацию диффузионной модели 
с обуславливанием на текст я не буду и предалагю выбор: 

1. дальше продолжать работать с cGAN
2. взять предобученную диффузионную модель и перенести ее на ваш домен

в случае (1) я предлагаю увеличить модель и генератора, и дискриминатора:
- сразу перейти к большей размерности картинки 
- добавить количество слоёв и ширину обеих моделей
- все conv transpose заменить на сочетание up scale + обычных conv слоёв
- интегрировать в свое обучение разного вида хаки: обучать дискриминатор и генератор не по-очереди, а делать 2 или 3 цикла обучения генератора на один цикл дискриминатора; использовать label smoothing для улучшения обучения, сглаживания задачи оптимизации; 
- при работе с текстовыми данными добавить несколько дополнительных слоёв к `nn.embedding`. посмотреть, какие бывают варианты реализации text encoder'ов, обучить что-то небольшое с нуля или взять маленькую предобученную модельку
- можно в дискриминаторе добавить к уже существующему выходу "реалистичность модели" еще и второй выход, насколько картинка соответствует тексту. кажется, это добавит больше информации генератору и усложнит задачу дискриминатора
- увеличить размер датасета в помощью аугментаций
- в тренировочном цикле перед обучением генератора стоит сгенерировать еще один батч картинок, на котором не обучался дискриминатор в этом цикле: мыдискриминатор же уже обновил свои веса по этим картинкам, так что он будет в какой-то степени хорошо уверен в своем предсказании и опять дискриминатору будет легко
- добавить graddient clipping, использовать EMA весов модели на инференсе

(практически) каждое из этих изменений предлагается делать по-отдельности, чтобы легко следить за вкладом каждого этапа улучшения модели и, при необходимости, его корректировать
для улучшения качества кода предлагается использовать wandb, в таком случае код будет чище, а трекать эксперименты будет удобнее


в случае (2) работа будет в каком-то смысле более инженерная и менее исследовательская
при выборе этого варианта, вам предлагается 
- найти небольшую диффузионную модель с возможностью обуславливания на текст, которая в обычном сетапе генерирует приемлемые картинки, но так себе воспроизводит домен логотипов, делает их какими-то слишком реалистичными или в целом недостаточно хорошего визуального качества
- разобраться с запуском и обучением таких моделей
- обучить эту модель по уже использвуемым данным, стартуя из выложенного на hf чекпоинта

в обоих случаях 
- предлагается продолжить использовать местрики FID и IS, но добавить CLIP-I для понимания, насколько близкие в исходному датасету получаются картинки, и CLIP-T, которая будет показывать, насколько хорошо модель обуславливается на текст
- важно перейти все-таки на датасферу, чтобы иметь бОльшие вычислительные ресурсы, иначе реализовать генерацию картинок 256х256 с адекватными визуальными характеристиками не получится
